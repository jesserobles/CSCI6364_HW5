{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 5:  CSCI 6364/4364\n",
    "\n",
    "In this assignment, you will become familiar with the deep learning library Pytorch through the construction of a feed-forward neural network and a convolutional neural network applied to the MNIST dataset.  In various parts of the notebook, there will be places to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and use the MNIST dataset from Homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = \"data_mnist.csv\"\n",
    "df = pd.read_csv(dataset_filename)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "X =  df.drop(['label'], axis=1).values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[-1]\n",
    "output_dim = 10\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,output_dim)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    " \n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 15.878024\t Accuracy:3.125%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 0.591852\t Accuracy:67.463%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 0.783195\t Accuracy:75.526%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 0.529619\t Accuracy:79.222%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.179729\t Accuracy:81.685%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.625295\t Accuracy:83.329%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.693083\t Accuracy:84.541%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.217769\t Accuracy:85.328%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.233654\t Accuracy:85.910%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.217472\t Accuracy:86.537%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.513734\t Accuracy:87.063%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.524939\t Accuracy:87.511%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.113853\t Accuracy:87.760%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.413980\t Accuracy:88.110%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.291666\t Accuracy:88.405%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.313035\t Accuracy:88.765%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.244497\t Accuracy:89.045%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.085711\t Accuracy:89.354%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.084314\t Accuracy:89.539%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.456434\t Accuracy:89.734%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.078515\t Accuracy:89.960%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.049967\t Accuracy:90.158%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.225198\t Accuracy:90.355%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.031064\t Accuracy:100.000%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.254659\t Accuracy:94.792%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.084824\t Accuracy:94.462%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.223156\t Accuracy:94.433%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.093699\t Accuracy:94.341%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.349378\t Accuracy:94.186%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.405387\t Accuracy:94.124%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.143141\t Accuracy:94.222%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.106206\t Accuracy:94.218%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.006425\t Accuracy:94.346%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.306649\t Accuracy:94.311%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.393115\t Accuracy:94.363%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.130902\t Accuracy:94.410%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.084647\t Accuracy:94.566%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.232673\t Accuracy:94.637%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.118436\t Accuracy:94.724%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.221722\t Accuracy:94.749%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.193777\t Accuracy:94.804%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.028956\t Accuracy:94.863%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.244555\t Accuracy:94.894%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.084364\t Accuracy:94.961%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.210716\t Accuracy:94.963%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.110485\t Accuracy:95.002%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.401287\t Accuracy:93.750%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.189411\t Accuracy:95.343%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.008422\t Accuracy:95.854%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.042362\t Accuracy:96.192%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.241360\t Accuracy:96.175%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.456578\t Accuracy:95.829%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.315612\t Accuracy:95.795%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.261059\t Accuracy:95.691%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.092441\t Accuracy:95.753%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.017296\t Accuracy:95.697%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.163931\t Accuracy:95.584%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.330377\t Accuracy:95.605%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.109994\t Accuracy:95.591%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.073613\t Accuracy:95.656%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.143365\t Accuracy:95.769%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.025474\t Accuracy:95.826%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.036838\t Accuracy:95.818%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.029354\t Accuracy:95.891%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.064070\t Accuracy:95.914%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.111923\t Accuracy:95.942%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.053527\t Accuracy:95.976%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.062151\t Accuracy:95.938%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.108962\t Accuracy:95.987%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.034563\t Accuracy:96.875%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.097530\t Accuracy:95.772%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.047142\t Accuracy:95.916%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.050622\t Accuracy:96.109%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.143793\t Accuracy:96.315%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.706849\t Accuracy:96.315%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.359394\t Accuracy:96.169%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.340882\t Accuracy:96.109%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.259388\t Accuracy:96.189%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.020075\t Accuracy:96.258%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.054094\t Accuracy:96.233%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.453795\t Accuracy:96.149%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.199933\t Accuracy:96.147%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.248840\t Accuracy:96.213%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.036283\t Accuracy:96.238%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.073086\t Accuracy:96.338%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.021111\t Accuracy:96.348%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.045226\t Accuracy:96.401%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.015997\t Accuracy:96.459%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.096387\t Accuracy:96.474%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.011263\t Accuracy:96.488%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.053692\t Accuracy:96.494%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.109832\t Accuracy:96.534%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.033572\t Accuracy:96.875%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.135926\t Accuracy:96.507%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.029713\t Accuracy:96.194%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.072946\t Accuracy:96.358%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.190877\t Accuracy:96.346%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.496058\t Accuracy:96.365%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.016650\t Accuracy:96.346%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.062089\t Accuracy:96.278%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.097039\t Accuracy:96.298%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.006048\t Accuracy:96.300%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.311072\t Accuracy:96.245%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.344583\t Accuracy:96.297%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.071245\t Accuracy:96.313%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.036842\t Accuracy:96.385%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.101760\t Accuracy:96.416%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.005955\t Accuracy:96.476%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.065845\t Accuracy:96.497%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.014497\t Accuracy:96.545%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.015002\t Accuracy:96.625%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.058196\t Accuracy:96.632%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.046609\t Accuracy:96.644%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.010121\t Accuracy:96.652%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.019214\t Accuracy:96.716%\n"
     ]
    }
   ],
   "source": [
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor(9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.eval()              # turn the model to evaluate mode\n",
    "index = 200\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "image = torch_X_test[index].float().unsqueeze(0)\n",
    "true_label = y_test[index]\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = mlp(image).argmax()   #gets the prediction for the image's class\n",
    "plt.imshow(image.numpy().reshape(28,28,1), cmap='gray_r');\n",
    "print(true_label)\n",
    "print(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35700, 1, 28, 28])\n",
      "torch.Size([6300, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch_X_train.view(-1, 1,28,28).float()\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float()\n",
    "print(torch_X_train.shape)\n",
    "print(torch_X_test.shape)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 17.491018\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 1.703722\t Accuracy:17.770%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 1.009868\t Accuracy:34.251%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 1.154488\t Accuracy:45.840%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 1.056982\t Accuracy:54.011%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.627523\t Accuracy:59.512%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.358505\t Accuracy:63.320%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.132880\t Accuracy:66.524%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.220809\t Accuracy:69.038%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.289793\t Accuracy:71.161%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.346210\t Accuracy:72.861%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.682445\t Accuracy:74.399%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.371773\t Accuracy:75.655%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.149076\t Accuracy:76.858%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.321230\t Accuracy:77.920%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.369620\t Accuracy:78.812%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.188525\t Accuracy:79.545%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.316570\t Accuracy:80.266%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.388716\t Accuracy:80.900%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.355938\t Accuracy:81.519%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.035882\t Accuracy:82.018%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.167438\t Accuracy:82.475%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.383795\t Accuracy:82.888%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.435282\t Accuracy:90.625%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.145045\t Accuracy:92.402%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.210413\t Accuracy:92.420%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.263403\t Accuracy:92.384%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.281719\t Accuracy:92.631%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.687903\t Accuracy:92.779%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.281953\t Accuracy:92.816%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.427460\t Accuracy:92.904%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.129305\t Accuracy:92.908%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.069423\t Accuracy:92.925%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.113218\t Accuracy:92.958%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.321160\t Accuracy:93.041%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.301912\t Accuracy:93.006%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.145145\t Accuracy:93.078%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.131641\t Accuracy:93.179%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.202060\t Accuracy:93.313%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.167930\t Accuracy:93.313%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.170522\t Accuracy:93.372%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.234927\t Accuracy:93.417%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.282239\t Accuracy:93.451%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.048641\t Accuracy:93.485%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.103245\t Accuracy:93.512%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.095123\t Accuracy:93.583%\n",
      "Epoch : 2 [0/35700 (0%)]\tLoss: 0.143320\t Accuracy:96.875%\n",
      "Epoch : 2 [1600/35700 (4%)]\tLoss: 0.231555\t Accuracy:94.975%\n",
      "Epoch : 2 [3200/35700 (9%)]\tLoss: 0.017496\t Accuracy:94.709%\n",
      "Epoch : 2 [4800/35700 (13%)]\tLoss: 0.127452\t Accuracy:94.454%\n",
      "Epoch : 2 [6400/35700 (18%)]\tLoss: 0.178156\t Accuracy:94.481%\n",
      "Epoch : 2 [8000/35700 (22%)]\tLoss: 0.191689\t Accuracy:94.360%\n",
      "Epoch : 2 [9600/35700 (27%)]\tLoss: 0.163249\t Accuracy:94.300%\n",
      "Epoch : 2 [11200/35700 (31%)]\tLoss: 0.158045\t Accuracy:94.382%\n",
      "Epoch : 2 [12800/35700 (36%)]\tLoss: 0.163277\t Accuracy:94.412%\n",
      "Epoch : 2 [14400/35700 (40%)]\tLoss: 0.131232\t Accuracy:94.436%\n",
      "Epoch : 2 [16000/35700 (45%)]\tLoss: 0.384372\t Accuracy:94.442%\n",
      "Epoch : 2 [17600/35700 (49%)]\tLoss: 0.434954\t Accuracy:94.419%\n",
      "Epoch : 2 [19200/35700 (54%)]\tLoss: 0.506953\t Accuracy:94.374%\n",
      "Epoch : 2 [20800/35700 (58%)]\tLoss: 0.042175\t Accuracy:94.302%\n",
      "Epoch : 2 [22400/35700 (63%)]\tLoss: 0.248954\t Accuracy:94.334%\n",
      "Epoch : 2 [24000/35700 (67%)]\tLoss: 0.117976\t Accuracy:94.391%\n",
      "Epoch : 2 [25600/35700 (72%)]\tLoss: 0.097598\t Accuracy:94.417%\n",
      "Epoch : 2 [27200/35700 (76%)]\tLoss: 0.245276\t Accuracy:94.418%\n",
      "Epoch : 2 [28800/35700 (81%)]\tLoss: 0.291835\t Accuracy:94.423%\n",
      "Epoch : 2 [30400/35700 (85%)]\tLoss: 0.174631\t Accuracy:94.456%\n",
      "Epoch : 2 [32000/35700 (90%)]\tLoss: 0.123771\t Accuracy:94.481%\n",
      "Epoch : 2 [33600/35700 (94%)]\tLoss: 0.009071\t Accuracy:94.505%\n",
      "Epoch : 2 [35200/35700 (99%)]\tLoss: 0.140799\t Accuracy:94.516%\n",
      "Epoch : 3 [0/35700 (0%)]\tLoss: 0.369417\t Accuracy:93.750%\n",
      "Epoch : 3 [1600/35700 (4%)]\tLoss: 0.223454\t Accuracy:94.179%\n",
      "Epoch : 3 [3200/35700 (9%)]\tLoss: 0.100380\t Accuracy:93.750%\n",
      "Epoch : 3 [4800/35700 (13%)]\tLoss: 0.103476\t Accuracy:94.185%\n",
      "Epoch : 3 [6400/35700 (18%)]\tLoss: 0.227542\t Accuracy:94.201%\n",
      "Epoch : 3 [8000/35700 (22%)]\tLoss: 0.205988\t Accuracy:94.460%\n",
      "Epoch : 3 [9600/35700 (27%)]\tLoss: 0.142538\t Accuracy:94.466%\n",
      "Epoch : 3 [11200/35700 (31%)]\tLoss: 0.432713\t Accuracy:94.569%\n",
      "Epoch : 3 [12800/35700 (36%)]\tLoss: 0.086672\t Accuracy:94.568%\n",
      "Epoch : 3 [14400/35700 (40%)]\tLoss: 0.094293\t Accuracy:94.581%\n",
      "Epoch : 3 [16000/35700 (45%)]\tLoss: 0.143815\t Accuracy:94.492%\n",
      "Epoch : 3 [17600/35700 (49%)]\tLoss: 0.359636\t Accuracy:94.595%\n",
      "Epoch : 3 [19200/35700 (54%)]\tLoss: 0.317731\t Accuracy:94.561%\n",
      "Epoch : 3 [20800/35700 (58%)]\tLoss: 0.009242\t Accuracy:94.643%\n",
      "Epoch : 3 [22400/35700 (63%)]\tLoss: 0.103791\t Accuracy:94.766%\n",
      "Epoch : 3 [24000/35700 (67%)]\tLoss: 0.084121\t Accuracy:94.815%\n",
      "Epoch : 3 [25600/35700 (72%)]\tLoss: 0.143214\t Accuracy:94.819%\n",
      "Epoch : 3 [27200/35700 (76%)]\tLoss: 0.102264\t Accuracy:94.859%\n",
      "Epoch : 3 [28800/35700 (81%)]\tLoss: 0.186154\t Accuracy:94.856%\n",
      "Epoch : 3 [30400/35700 (85%)]\tLoss: 0.088187\t Accuracy:94.867%\n",
      "Epoch : 3 [32000/35700 (90%)]\tLoss: 0.044488\t Accuracy:94.849%\n",
      "Epoch : 3 [33600/35700 (94%)]\tLoss: 0.138897\t Accuracy:94.892%\n",
      "Epoch : 3 [35200/35700 (99%)]\tLoss: 0.095473\t Accuracy:94.928%\n",
      "Epoch : 4 [0/35700 (0%)]\tLoss: 0.271261\t Accuracy:90.625%\n",
      "Epoch : 4 [1600/35700 (4%)]\tLoss: 0.115738\t Accuracy:95.588%\n",
      "Epoch : 4 [3200/35700 (9%)]\tLoss: 0.017479\t Accuracy:96.009%\n",
      "Epoch : 4 [4800/35700 (13%)]\tLoss: 0.512698\t Accuracy:95.944%\n",
      "Epoch : 4 [6400/35700 (18%)]\tLoss: 0.209025\t Accuracy:95.600%\n",
      "Epoch : 4 [8000/35700 (22%)]\tLoss: 0.492747\t Accuracy:95.605%\n",
      "Epoch : 4 [9600/35700 (27%)]\tLoss: 0.078214\t Accuracy:95.546%\n",
      "Epoch : 4 [11200/35700 (31%)]\tLoss: 0.037404\t Accuracy:95.522%\n",
      "Epoch : 4 [12800/35700 (36%)]\tLoss: 0.010457\t Accuracy:95.597%\n",
      "Epoch : 4 [14400/35700 (40%)]\tLoss: 0.114197\t Accuracy:95.621%\n",
      "Epoch : 4 [16000/35700 (45%)]\tLoss: 0.114526\t Accuracy:95.696%\n",
      "Epoch : 4 [17600/35700 (49%)]\tLoss: 0.364283\t Accuracy:95.678%\n",
      "Epoch : 4 [19200/35700 (54%)]\tLoss: 0.090061\t Accuracy:95.632%\n",
      "Epoch : 4 [20800/35700 (58%)]\tLoss: 0.039895\t Accuracy:95.646%\n",
      "Epoch : 4 [22400/35700 (63%)]\tLoss: 0.382673\t Accuracy:95.707%\n",
      "Epoch : 4 [24000/35700 (67%)]\tLoss: 0.020053\t Accuracy:95.706%\n",
      "Epoch : 4 [25600/35700 (72%)]\tLoss: 0.175055\t Accuracy:95.681%\n",
      "Epoch : 4 [27200/35700 (76%)]\tLoss: 0.168504\t Accuracy:95.656%\n",
      "Epoch : 4 [28800/35700 (81%)]\tLoss: 0.211810\t Accuracy:95.682%\n",
      "Epoch : 4 [30400/35700 (85%)]\tLoss: 0.367221\t Accuracy:95.662%\n",
      "Epoch : 4 [32000/35700 (90%)]\tLoss: 0.054837\t Accuracy:95.692%\n",
      "Epoch : 4 [33600/35700 (94%)]\tLoss: 0.087515\t Accuracy:95.689%\n",
      "Epoch : 4 [35200/35700 (99%)]\tLoss: 0.093070\t Accuracy:95.672%\n"
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.eval()              # turn the model to evaluate mode\n",
    "index = 100\n",
    "torch_X_test = torch_X_test.view(-1,1,28,28).float().type(torch.LongTensor)\n",
    "image = torch_X_test[index].float().unsqueeze(0)\n",
    "true_label = y_test[index]\n",
    "with torch.no_grad():     # does not calculate gradient\n",
    "    class_index = cnn(image).argmax()   #gets the prediction for the image's class\n",
    "plt.imshow(image.numpy().reshape(28,28,1), cmap='gray_r');\n",
    "print(true_label)\n",
    "print(class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the performance of the MLP and CNN models? Performance can include training time, accuracy, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP vs. CNN\n",
    "The training time for MLP is much faster than for CNN. The accuracy of the model also increases faster for MLP than for CNN, implying that it converges faster. If we look at the output where each line represents 50 batches, both models start at around 15%, and MLP jumps to about 60-70% in the next printed line. CNN takes about 7 lines to get to that value. Additionally, MLP seems to achieve higher accuracy. Even after 150 epochs, the CNN remains at about 96-97% accuracy, while the MLP achieves 99% accuracy. The good performance of the MLP is likely the result of this dataset being simple images that are very similar to each other (same size, similar pixels tend to be the ones that are shaded, etc.). For more complex image tasks, the CNN is likely to outper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit: Describe the below code and the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code modifies the gradients in the x tensor so it misclassifies a digit. It first gets the model's inference for the image at index 100 by calculating the logit output and getting the argmax. It then loops, and in each iteration calculates the inference/logits/argmax. The first time they are going to be the same as what was calculated before the loop, so it will not satisfy the if statement and thus not break. The code then modifies the logits at the predicted digit index and calculates the loss, updating the gradients. These updates eventually cause the model to update the weights such that the inference for that image, and likely for images similar to that one, to be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init idx: 6\n",
      "9.713150024414062 -9.870042413240299e-05 -9.713248252868652\n",
      "\n",
      "Job done, breaking\n",
      "tensor([-2.1283, -2.0920, -2.2709, -2.4545, -2.4132, -2.5092, -2.5033, -2.3471,\n",
      "        -2.1452, -2.2729])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cnn\n",
    "#torch_X_test = torch_X_test.view(-1,1,28,28).float().type(torch.LongTensor)\n",
    "x = torch_X_test[index].float().clone()\n",
    "x.requires_grad_(True)\n",
    "with torch.no_grad():\n",
    "    logits = model(x.unsqueeze(0)).squeeze()\n",
    "    IMX = torch.argmax(logits)\n",
    "print(\"Init idx:\",IMX.item())\n",
    "\n",
    "lr=.01\n",
    "while True:\n",
    "    logits = model(x.unsqueeze(0)).squeeze()\n",
    "    \n",
    "    imx = torch.argmax(logits)\n",
    "    if imx!=IMX: \n",
    "        print(\"Job done, breaking\")\n",
    "        break\n",
    "    y = logits.clone()\n",
    "    y[imx] = -99\n",
    "    loss = logits.max() - y.max() \n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    x.data.sub_(lr*x.grad.data)\n",
    "    print(loss.item(),logits.max().item(), y.max().item() )\n",
    "    print()\n",
    "    x.grad.data.zero_()\n",
    "    x.data.sub_(x.data.min())\n",
    "    x.data.mul_(1/x.data.max())\n",
    "    \n",
    "with torch.no_grad():\n",
    "    print(model(x.unsqueeze(0)).squeeze())\n",
    "\n",
    "plt.imshow(x.detach().cpu().numpy().transpose(1,2,0).reshape(28,28));torch.argmax(model(x.unsqueeze(0))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
